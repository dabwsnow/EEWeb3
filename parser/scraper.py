import requests
from bs4 import BeautifulSoup
import sys
import os
import re
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.database import SessionLocal
from app import models
from tqdm import tqdm
import time

# –ú–∞–ø–ø–∏–Ω–≥ –ø—Ä–æ—Ñ–∏–ª–µ–π
PROFILE_MODELS = {
    'e12': models.QuestionE12,
    'e13': models.QuestionE13,
    'ee08': models.QuestionINF02,
    'inf03ee09e14': models.QuestionINF03,
    'inf04': models.QuestionINF04
}

PROFILE_NAMES = {
    'e12': 'E.12',
    'e13': 'E.13',
    'ee08': 'INF.02',
    'inf03ee09e14': 'INF.03',
    'inf04': 'INF.04'
}

PROFILES_URLS = {
    'e12': 'https://www.praktycznyegzamin.pl/e12/teoria/wszystko/',
    'e13': 'https://www.praktycznyegzamin.pl/e13/teoria/wszystko/',
    'ee08': 'https://www.praktycznyegzamin.pl/ee08/teoria/wszystko/',
    'inf03ee09e14': 'https://www.praktycznyegzamin.pl/inf03ee09e14/teoria/wszystko/',
    'inf04': 'https://www.praktycznyegzamin.pl/inf04/teoria/wszystko/'
}

def download_image(image_url, profile_name, page_url):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"""
    try:
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        img_dir = os.path.join(project_root, "static", "images", profile_name)
        os.makedirs(img_dir, exist_ok=True)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π URL - –ü–†–û–°–¢–û –î–û–ë–ê–í–õ–Ø–ï–ú –ö page_url
        if image_url.startswith('http'):
            full_image_url = image_url
        else:
            # –í–°–ï –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ page_url
            full_image_url = page_url + image_url
        
        print(f"      ‚Üí –ü–æ–ª–Ω—ã–π URL: {full_image_url}")
        
        # –î–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ —É–±–∏—Ä–∞–µ–º old/
        image_name = image_url.replace('old/', '').split("/")[-1]
        image_path = os.path.join(img_dir, image_name)
        
        # –ï—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å
        if os.path.exists(image_path) and os.path.getsize(image_path) > 0:
            print(f"      ‚Üí –£–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ")
            return f"/static/images/{profile_name}/{image_name}"
        
        # –°–∫–∞—á–∏–≤–∞–µ–º
        img_response = requests.get(full_image_url, timeout=10)
        img_response.raise_for_status()
        
        with open(image_path, "wb") as f:
            f.write(img_response.content)
        
        print(f"      ‚Üí –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {image_path}")
        
        # –í–û–ó–í–†–ê–©–ê–ï–ú –ü–£–¢–¨ –î–õ–Ø –ë–î (–±–µ–∑ old/)
        return f"/static/images/{profile_name}/{image_name}"
    
    except Exception as e:
        print(f"      ‚ùå –û—à–∏–±–∫–∞: {e}")
        return None

def parse_page(url, profile_name):
    """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
    print(f"\nüîç –ü–∞—Ä—Å–∏–Ω–≥: {url}")
    
    try:
        response = requests.get(url, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")
        
        question_divs = soup.find_all("div", class_="question")
        print(f"  üìù –ù–∞–π–¥–µ–Ω–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {len(question_divs)}")
        
        if not question_divs:
            return []
        
        questions_data = []
        images_found = 0
        
        for q_div in question_divs:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title_div = q_div.find("div", class_="title")
            if not title_div:
                continue
            
            title = title_div.text.strip()
            title = re.sub(r'^\d+\.\s*', '', title)
            
            # –û—Ç–≤–µ—Ç—ã
            answers = []
            correct = None
            
            for i, ans in enumerate(q_div.find_all("div", class_="answer")):
                text = ans.text.strip()
                answers.append(text)
                if "correct" in ans.get("class", []):
                    correct = i
            
            while len(answers) < 4:
                answers.append("")
            
            clean_answers = []
            for ans in answers:
                clean = re.sub(r'^\s*[A-D]\.\s*', '', ans).strip()
                clean_answers.append(clean)
            
            correct_letter = chr(97 + correct) if correct is not None else None
            
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ - –ë–ï–ó –§–ò–õ–¨–¢–†–ê old/
            image_path = None
            img_tag = q_div.find("div", class_="image")
            
            if img_tag and img_tag.img:
                image_url = img_tag.img.get("src")
                
                if image_url:
                    print(f"    üñºÔ∏è  –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_url}")
                    image_path = download_image(image_url, profile_name, url)
                    if image_path:
                        images_found += 1
                        print(f"    ‚úÖ –°–∫–∞—á–∞–Ω–æ: {image_path}")
                    else:
                        print(f"    ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å")
            
            if not title or correct_letter is None:
                continue
            
            questions_data.append({
                'question': title,
                'answer_a': clean_answers[0],
                'answer_b': clean_answers[1],
                'answer_c': clean_answers[2],
                'answer_d': clean_answers[3],
                'correct_answer': correct_letter,
                'image_url': image_path
            })
        
        print(f"  üñºÔ∏è  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞–π–¥–µ–Ω–æ –∏ —Å–∫–∞—á–∞–Ω–æ: {images_found}")
        
        return questions_data
    
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return []
def scrape_profile(profile_key, base_url):
    """–ü–∞—Ä—Å–∏—Ç –ø—Ä–æ—Ñ–∏–ª—å"""
    model = PROFILE_MODELS.get(profile_key)
    profile_name = PROFILE_NAMES.get(profile_key)
    
    if not model:
        print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å: {profile_key}")
        return
    
    print(f"\n{'='*60}")
    print(f"üìö {profile_name} ‚Üí {model.__tablename__}")
    print(f"{'='*60}")
    
    questions_data = parse_page(base_url, profile_key)
    
    db = SessionLocal()
    added = 0
    updated = 0
    skipped = 0
    images = 0
    
    try:
        for q_data in tqdm(questions_data, desc="  üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ"):
            existing = db.query(model).filter(
                model.question == q_data['question']
            ).first()
            
            if existing:
                # –û–¢–õ–ê–î–ö–ê
                print(f"\n    üîç –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å")
                print(f"    üìù –í–æ–ø—Ä–æ—Å: {q_data['question'][:50]}...")
                print(f"    üñºÔ∏è  –ù–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {q_data['image_url']}")
                print(f"    üñºÔ∏è  –°—Ç–∞—Ä–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {existing.image_url}")
                
                # –û–ë–ù–û–í–õ–Ø–ï–ú –ï–°–õ–ò –ï–°–¢–¨ –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ï
                if q_data['image_url'] and not existing.image_url:
                    existing.image_url = q_data['image_url']
                    updated += 1
                    images += 1
                    print(f"    ‚úÖ –û–ë–ù–û–í–õ–Ø–ï–ú!")
                else:
                    print(f"    ‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    if not q_data['image_url']:
                        print(f"       –ü—Ä–∏—á–∏–Ω–∞: –Ω–µ—Ç –Ω–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
                    if existing.image_url:
                        print(f"       –ü—Ä–∏—á–∏–Ω–∞: —É–∂–µ –µ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
                    skipped += 1
                continue
            
            # –ü–†–û–í–ï–†–Ø–ï–ú –ß–¢–û –ü–£–¢–¨ –ö –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Æ –ï–°–¢–¨
            if q_data['image_url']:
                images += 1
                print(f"\n    üíæ –°–æ—Ö—Ä–∞–Ω—è—é —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º: {q_data['image_url'][:50]}...")
            
            question = model(
                question=q_data['question'],
                answer_a=q_data['answer_a'],
                answer_b=q_data['answer_b'],
                answer_c=q_data['answer_c'],
                answer_d=q_data['answer_d'],
                correct_answer=q_data['correct_answer'],
                image_url=q_data['image_url'],
                explanation=""
            )
            
            db.add(question)
            added += 1
        
        db.commit()
        
        print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç:")
        print(f"   üìù –í—Å–µ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ: {added}")
        print(f"   üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–æ: {updated}")
        print(f"   üñºÔ∏è  –° –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏: {images}")
        print(f"   ‚è≠Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped}\n")
    
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        db.rollback()
    finally:
        db.close()

def main():
    print("\nüöÄ –°–¢–ê–†–¢ –ü–ê–†–°–ï–†–ê\n")
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    os.makedirs(os.path.join(project_root, "static", "images"), exist_ok=True)
    
    # –ü–∞—Ä—Å–∏–º –≤—Å–µ –ø—Ä–æ—Ñ–∏–ª–∏
    for profile_key, base_url in PROFILES_URLS.items():
        try:
            scrape_profile(profile_key, base_url)
            time.sleep(1)
        except Exception as e:
            print(f"‚ùå {profile_key}: {e}")
            continue
    
    print("üéâ –ì–û–¢–û–í–û!\n")

if __name__ == "__main__":
    main()